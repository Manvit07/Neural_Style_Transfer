{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd2ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just trying out neural style transfer stuff üòÖ\n",
    "\n",
    "# First let's install the library that helps us\n",
    "!pip install torch torchvision\n",
    "\n",
    "# importing some useful libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "# resize images to something smallish\n",
    "imsize = 256\n",
    "\n",
    "# transforms to convert images to tensor and normalize them\n",
    "loader = transforms.Compose([\n",
    "    transforms.Resize((imsize, imsize)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# this function loads and prepares the image\n",
    "def image_loader(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = loader(image).unsqueeze(0)  # add batch dimension\n",
    "    return image.to(\"cuda\" if torch.cuda.is_available() else \"cpu\", torch.float)\n",
    "\n",
    "# now load your content and style images\n",
    "# you can upload your own images in colab using the upload button\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# replace these with your actual file names\n",
    "content_img = image_loader(\"your_content_image.jpg\")\n",
    "style_img = image_loader(\"your_style_image.jpg\")\n",
    "\n",
    "# quick function to show images\n",
    "def imshow(tensor, title=None):\n",
    "    image = tensor.cpu().clone()\n",
    "    image = image.squeeze(0)\n",
    "    image = transforms.ToPILImage()(image)\n",
    "    plt.imshow(image)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# display both images to see\n",
    "imshow(content_img, title='Content Image')\n",
    "imshow(style_img, title='Style Image')\n",
    "\n",
    "# use VGG19 model from torchvision\n",
    "cnn = models.vgg19(pretrained=True).features.to(\"cuda\" if torch.cuda.is_available() else \"cpu\").eval()\n",
    "\n",
    "# mean and std for normalizing input image\n",
    "normalization_mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "normalization_std = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "# simple class to normalize\n",
    "class Normalization(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalization, self).__init__()\n",
    "        self.mean = mean.clone().detach().view(-1, 1, 1)\n",
    "        self.std = std.clone().detach().view(-1, 1, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return (img - self.mean) / self.std\n",
    "\n",
    "# content loss to compare features\n",
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self, target):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        self.target = target.detach()\n",
    "    def forward(self, input):\n",
    "        self.loss = nn.functional.mse_loss(input, self.target)\n",
    "        return input\n",
    "\n",
    "# style loss to compare textures/patterns\n",
    "def gram_matrix(input):\n",
    "    a, b, c, d = input.size()\n",
    "    features = input.view(a * b, c * d)\n",
    "    G = torch.mm(features, features.t())\n",
    "    return G.div(a * b * c * d)\n",
    "\n",
    "class StyleLoss(nn.Module):\n",
    "    def __init__(self, target_feature):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = gram_matrix(target_feature).detach()\n",
    "    def forward(self, input):\n",
    "        G = gram_matrix(input)\n",
    "        self.loss = nn.functional.mse_loss(G, self.target)\n",
    "        return input\n",
    "\n",
    "# layers where we want to compute style and content losses\n",
    "content_layers = ['conv_4']\n",
    "style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "\n",
    "# building the model\n",
    "def get_style_model_and_losses(cnn, norm_mean, norm_std, style_img, content_img):\n",
    "    cnn = copy.deepcopy(cnn)\n",
    "    normalization = Normalization(norm_mean, norm_std).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    content_losses = []\n",
    "    style_losses = []\n",
    "\n",
    "    model = nn.Sequential(normalization)\n",
    "\n",
    "    i = 0  # increment when we see a conv layer\n",
    "    for layer in cnn.children():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            i += 1\n",
    "            name = 'conv_{}'.format(i)\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            name = 'relu_{}'.format(i)\n",
    "            layer = nn.ReLU(inplace=False)\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            name = 'pool_{}'.format(i)\n",
    "        elif isinstance(layer, nn.BatchNorm2d):\n",
    "            name = 'bn_{}'.format(i)\n",
    "        else:\n",
    "            name = 'layer_{}'.format(i)\n",
    "\n",
    "        model.add_module(name, layer)\n",
    "\n",
    "        if name in content_layers:\n",
    "            target = model(content_img).detach()\n",
    "            content_loss = ContentLoss(target)\n",
    "            model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
    "            content_losses.append(content_loss)\n",
    "\n",
    "        if name in style_layers:\n",
    "            target_feature = model(style_img).detach()\n",
    "            style_loss = StyleLoss(target_feature)\n",
    "            model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
    "            style_losses.append(style_loss)\n",
    "\n",
    "    # trim off the layers after the last content/style loss\n",
    "    for i in range(len(model) - 1, -1, -1):\n",
    "        if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
    "            break\n",
    "    model = model[:i+1]\n",
    "\n",
    "    return model, style_losses, content_losses\n",
    "\n",
    "# we start from content image\n",
    "input_img = content_img.clone()\n",
    "\n",
    "# make it require gradient\n",
    "input_img.requires_grad_(True)\n",
    "\n",
    "# get the model and losses\n",
    "model, style_losses, content_losses = get_style_model_and_losses(\n",
    "    cnn, normalization_mean, normalization_std, style_img, content_img\n",
    ")\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.LBFGS([input_img])\n",
    "\n",
    "# run the style transfer\n",
    "print(\"Working on it... might take a while ‚è≥\")\n",
    "run = [0]\n",
    "while run[0] <= 300:\n",
    "\n",
    "    def closure():\n",
    "        input_img.data.clamp_(0, 1)\n",
    "        optimizer.zero_grad()\n",
    "        model(input_img)\n",
    "        style_score = 0\n",
    "        content_score = 0\n",
    "\n",
    "        for sl in style_losses:\n",
    "            style_score += sl.loss\n",
    "        for cl in content_losses:\n",
    "            content_score += cl.loss\n",
    "\n",
    "        loss = style_score * 1000000 + content_score\n",
    "        loss.backward()\n",
    "        run[0] += 1\n",
    "\n",
    "        if run[0] % 50 == 0:\n",
    "            print(\"step {}: Style Loss : {:4f} Content Loss: {:4f}\".format(run[0], style_score.item(), content_score.item()))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "# clamp final image and show it\n",
    "input_img.data.clamp_(0, 1)\n",
    "imshow(input_img, title='Stylized Image ‚ú®')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}